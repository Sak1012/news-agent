{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# News Agent Debug Notebook\n",
        "\n",
        "This notebook mirrors the Python modules so you can tinker with the agent, adjust providers, and try out queries interactively."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "import os\n",
        "import re\n",
        "from collections import Counter\n",
        "from dataclasses import dataclass, field, asdict\n",
        "from datetime import datetime, timedelta, timezone\n",
        "from typing import Iterable, List, Mapping, Optional\n",
        "from urllib.parse import urlparse\n",
        "\n",
        "import feedparser\n",
        "import requests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def _split_csv(value: Optional[str]) -> List[str]:\n",
        "    if not value:\n",
        "        return []\n",
        "    return [item.strip() for item in value.split(\",\") if item.strip()]\n",
        "\n",
        "\n",
        "@dataclass(slots=True)\n",
        "class AgentConfig:\n",
        "    \"\"\"Runtime configuration for the news agent.\"\"\"\n",
        "\n",
        "    newsapi_key: Optional[str] = None\n",
        "    default_limit: int = 10\n",
        "    allowed_domains: List[str] = field(default_factory=list)\n",
        "\n",
        "    @classmethod\n",
        "    def from_env(cls) -> \"AgentConfig\":\n",
        "        return cls(\n",
        "            newsapi_key=os.getenv(\"NEWSAPI_KEY\"),\n",
        "            default_limit=int(os.getenv(\"NEWS_AGENT_DEFAULT_LIMIT\", \"10\")),\n",
        "            allowed_domains=_split_csv(os.getenv(\"NEWS_AGENT_ALLOWED_DOMAINS\")),\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "@dataclass(slots=True)\n",
        "class RawArticle:\n",
        "    \"\"\"Raw article data collected from a provider.\"\"\"\n",
        "\n",
        "    title: str\n",
        "    url: str\n",
        "    source: str\n",
        "    published_at: Optional[datetime]\n",
        "    content: Optional[str]\n",
        "    description: Optional[str]\n",
        "\n",
        "\n",
        "@dataclass(slots=True)\n",
        "class NewsItem:\n",
        "    \"\"\"Structured representation of a processed article.\"\"\"\n",
        "\n",
        "    title: str\n",
        "    url: str\n",
        "    source: str\n",
        "    published_at: Optional[datetime]\n",
        "    summary: Optional[str]\n",
        "    sentiment: str\n",
        "    sentiment_score: float\n",
        "    excerpt: Optional[str] = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "WORD_RE = re.compile(r\"[A-Za-z']+\")\n",
        "\n",
        "\n",
        "def summarize(text: Optional[str], max_sentences: int = 2) -> Optional[str]:\n",
        "    if not text:\n",
        "        return None\n",
        "    sentences = _split_sentences(text)\n",
        "    if not sentences:\n",
        "        return None\n",
        "    if len(sentences) <= max_sentences:\n",
        "        return \" \".join(sentences)\n",
        "    scores = _score_sentences(sentences)\n",
        "    ranked = sorted(enumerate(sentences), key=lambda item: scores.get(item[0], 0.0), reverse=True)\n",
        "    top_indices = sorted(idx for idx, _ in ranked[:max_sentences])\n",
        "    return \" \".join(sentences[idx] for idx in top_indices)\n",
        "\n",
        "\n",
        "def _split_sentences(text: str) -> List[str]:\n",
        "    split = re.split(r\"(?<=[.!?])\\s+\", text.strip())\n",
        "    return [sentence.strip() for sentence in split if sentence.strip()]\n",
        "\n",
        "\n",
        "def _score_sentences(sentences: Iterable[str]) -> dict[int, float]:\n",
        "    words = [word.lower() for sentence in sentences for word in WORD_RE.findall(sentence)]\n",
        "    if not words:\n",
        "        return {}\n",
        "    freq = Counter(words)\n",
        "    max_freq = max(freq.values())\n",
        "    normalized = {word: count / max_freq for word, count in freq.items()}\n",
        "    scores: dict[int, float] = {}\n",
        "    for idx, sentence in enumerate(sentences):\n",
        "        tokens = WORD_RE.findall(sentence)\n",
        "        if not tokens:\n",
        "            continue\n",
        "        scores[idx] = sum(normalized.get(word.lower(), 0.0) for word in tokens) / len(tokens)\n",
        "    return scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "POSITIVE_TOKENS = {\n",
        "    \"growth\",\n",
        "    \"improve\",\n",
        "    \"improving\",\n",
        "    \"surge\",\n",
        "    \"strong\",\n",
        "    \"beat\",\n",
        "    \"record\",\n",
        "    \"gain\",\n",
        "    \"positive\",\n",
        "    \"optimistic\",\n",
        "    \"upbeat\",\n",
        "    \"increase\",\n",
        "    \"exceed\",\n",
        "    \"sustainable\",\n",
        "    \"sustainability\",\n",
        "    \"expansion\",\n",
        "}\n",
        "\n",
        "NEGATIVE_TOKENS = {\n",
        "    \"loss\",\n",
        "    \"decline\",\n",
        "    \"drop\",\n",
        "    \"warning\",\n",
        "    \"weak\",\n",
        "    \"downturn\",\n",
        "    \"concern\",\n",
        "    \"miss\",\n",
        "    \"lawsuit\",\n",
        "    \"negative\",\n",
        "    \"risk\",\n",
        "    \"regulatory\",\n",
        "    \"penalty\",\n",
        "    \"fraud\",\n",
        "    \"downgrade\",\n",
        "}\n",
        "\n",
        "\n",
        "def score_sentiment(text: Optional[str]) -> tuple[str, float]:\n",
        "    if not text:\n",
        "        return \"neutral\", 0.0\n",
        "    lowered = text.lower()\n",
        "    pos_hits = sum(lowered.count(token) for token in POSITIVE_TOKENS)\n",
        "    neg_hits = sum(lowered.count(token) for token in NEGATIVE_TOKENS)\n",
        "    total = pos_hits + neg_hits\n",
        "    if total == 0:\n",
        "        return \"neutral\", 0.0\n",
        "    score = (pos_hits - neg_hits) / max(total, 1)\n",
        "    if score > 0.2:\n",
        "        return \"positive\", score\n",
        "    if score < -0.2:\n",
        "        return \"negative\", score\n",
        "    return \"neutral\", score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class BaseProvider:\n",
        "    \"\"\"Abstract base class for content providers.\"\"\"\n",
        "\n",
        "    def fetch(self, query: str, limit: int = 10, **kwargs: Mapping[str, object]) -> Iterable[RawArticle]:\n",
        "        raise NotImplementedError"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class NewsAPIProvider(BaseProvider):\n",
        "    \"\"\"Fetch articles from newsapi.org when an API key is available.\"\"\"\n",
        "\n",
        "    BASE_URL = \"https://newsapi.org/v2/everything\"\n",
        "\n",
        "    def __init__(self, api_key: str) -> None:\n",
        "        if not api_key:\n",
        "            raise ValueError(\"NewsAPIProvider requires an API key\")\n",
        "        self._api_key = api_key\n",
        "\n",
        "    def fetch(self, query: str, limit: int = 10, **kwargs: Mapping[str, object]) -> Iterable[RawArticle]:\n",
        "        params = {\n",
        "            \"q\": query,\n",
        "            \"pageSize\": limit,\n",
        "            \"language\": kwargs.get(\"language\", \"en\"),\n",
        "            \"sortBy\": kwargs.get(\"sort_by\", \"publishedAt\"),\n",
        "        }\n",
        "        response = requests.get(\n",
        "            self.BASE_URL,\n",
        "            params=params,\n",
        "            headers={\"Authorization\": self._api_key},\n",
        "            timeout=10,\n",
        "        )\n",
        "        response.raise_for_status()\n",
        "        payload = response.json()\n",
        "        for article in payload.get(\"articles\", []):\n",
        "            yield RawArticle(\n",
        "                title=article.get(\"title\") or \"Untitled\",\n",
        "                url=article.get(\"url\") or \"\",\n",
        "                source=(article.get(\"source\") or {}).get(\"name\") or \"Unknown\",\n",
        "                published_at=_parse_date(article.get(\"publishedAt\")),\n",
        "                content=article.get(\"content\"),\n",
        "                description=article.get(\"description\"),\n",
        "            )\n",
        "\n",
        "\n",
        "def _parse_date(value: Optional[str]) -> Optional[datetime]:\n",
        "    if not value:\n",
        "        return None\n",
        "    try:\n",
        "        return datetime.fromisoformat(value.replace(\"Z\", \"+00:00\"))\n",
        "    except ValueError:\n",
        "        return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class WiredRSSProvider(BaseProvider):\n",
        "    \"\"\"Fetches and filters articles from Wired RSS feeds.\"\"\"\n",
        "\n",
        "    DEFAULT_SECTIONS = {\n",
        "        \"business\": \"https://www.wired.com/feed/category/business/latest/rss\",\n",
        "        \"science\": \"https://www.wired.com/feed/category/science/latest/rss\",\n",
        "    }\n",
        "\n",
        "    def __init__(self, sections: Mapping[str, str] | None = None) -> None:\n",
        "        self._sections = dict(sections or self.DEFAULT_SECTIONS)\n",
        "\n",
        "    def fetch(self, query: str, limit: int = 10, **kwargs: Mapping[str, object]) -> Iterable[RawArticle]:\n",
        "        normalized_query = query.lower()\n",
        "        results: List[RawArticle] = []\n",
        "        for section, url in self._sections.items():\n",
        "            try:\n",
        "                response = requests.get(url, timeout=10)\n",
        "                response.raise_for_status()\n",
        "            except Exception:\n",
        "                continue\n",
        "            feed = feedparser.parse(response.content)\n",
        "            for entry in feed.entries or []:\n",
        "                if normalized_query not in _entry_text(entry):\n",
        "                    continue\n",
        "                results.append(\n",
        "                    RawArticle(\n",
        "                        title=entry.get(\"title\") or f\"Wired {section.title()} Update\",\n",
        "                        url=entry.get(\"link\") or \"\",\n",
        "                        source=f\"Wired {section.title()}\",\n",
        "                        published_at=_parse_published(entry),\n",
        "                        content=_get_content(entry),\n",
        "                        description=entry.get(\"summary\"),\n",
        "                    )\n",
        "                )\n",
        "                if len(results) >= limit:\n",
        "                    return results\n",
        "        return results\n",
        "\n",
        "\n",
        "def _entry_text(entry: Mapping[str, object]) -> str:\n",
        "    title = str(entry.get(\"title\", \"\"))\n",
        "    summary = str(entry.get(\"summary\", \"\"))\n",
        "    content = \"\"\n",
        "    contents = entry.get(\"content\")\n",
        "    if contents:\n",
        "        try:\n",
        "            content = \" \".join(part.get(\"value\", \"\") for part in contents if isinstance(part, Mapping))\n",
        "        except Exception:\n",
        "            content = \"\"\n",
        "    return f\"{title} {summary} {content}\".lower()\n",
        "\n",
        "\n",
        "def _get_content(entry: Mapping[str, object]) -> Optional[str]:\n",
        "    contents = entry.get(\"content\")\n",
        "    if contents:\n",
        "        parts: List[str] = []\n",
        "        for part in contents:\n",
        "            if isinstance(part, Mapping):\n",
        "                value = part.get(\"value\")\n",
        "                if isinstance(value, str):\n",
        "                    parts.append(value)\n",
        "        if parts:\n",
        "            return \"\\n\\n\".join(parts)\n",
        "    summary = entry.get(\"summary\")\n",
        "    return summary if isinstance(summary, str) else None\n",
        "\n",
        "\n",
        "def _parse_published(entry: Mapping[str, object]) -> Optional[datetime]:\n",
        "    published_parsed = entry.get(\"published_parsed\")\n",
        "    if published_parsed:\n",
        "        try:\n",
        "            return datetime(*published_parsed[:6], tzinfo=timezone.utc)\n",
        "        except Exception:\n",
        "            pass\n",
        "    updated = entry.get(\"updated_parsed\")\n",
        "    if updated:\n",
        "        try:\n",
        "            return datetime(*updated[:6], tzinfo=timezone.utc)\n",
        "        except Exception:\n",
        "            pass\n",
        "    return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class MockProvider(BaseProvider):\n",
        "    \"\"\"Returns hard-coded articles for offline development.\"\"\"\n",
        "\n",
        "    def fetch(self, query: str, limit: int = 10, **kwargs) -> Iterable[RawArticle]:\n",
        "        now = datetime.utcnow()\n",
        "        sample = [\n",
        "            RawArticle(\n",
        "                title=f\"{query.title()} expands sustainability efforts\",\n",
        "                url=\"https://example.com/sustainability\",\n",
        "                source=\"Example News\",\n",
        "                published_at=now - timedelta(hours=2),\n",
        "                content=(\n",
        "                    f\"{query} announced new sustainability targets aimed at reducing emissions by 30% \"\n",
        "                    \"over the next five years. The initiative includes investments in renewable energy \"\n",
        "                    \"and supply chain transparency.\"\n",
        "                ),\n",
        "                description=\"Company targets lower emissions and greener supply chains.\",\n",
        "            ),\n",
        "            RawArticle(\n",
        "                title=f\"Analysts debate {query} quarterly earnings\",\n",
        "                url=\"https://example.com/earnings\",\n",
        "                source=\"Market Watchers\",\n",
        "                published_at=now - timedelta(days=1),\n",
        "                content=(\n",
        "                    f\"Market analysts offered mixed reactions to {query}'s latest earnings report, citing \"\n",
        "                    \"flat revenue growth but improving operating margins. Investor sentiment appears \"\n",
        "                    \"cautious heading into the next quarter.\"\n",
        "                ),\n",
        "                description=\"Mixed analyst sentiment following the latest results.\",\n",
        "            ),\n",
        "        ]\n",
        "        return sample[:limit]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7d51075e",
      "metadata": {},
      "outputs": [],
      "source": [
        "class NewsAgent:\n",
        "    \"\"\"Aggregates, summarizes, and scores news articles.\"\"\"\n",
        "\n",
        "    def __init__(self, config: Optional[AgentConfig] = None, providers: Optional[Iterable[BaseProvider]] = None) -> None:\n",
        "        self.config = config or AgentConfig.from_env()\n",
        "        if providers is not None:\n",
        "            self.providers = list(providers)\n",
        "        else:\n",
        "            self.providers = self._build_providers()\n",
        "        if not self.providers:\n",
        "            raise RuntimeError(\"No providers configured for NewsAgent\")\n",
        "\n",
        "    def _build_providers(self) -> List[BaseProvider]:\n",
        "        providers: List[BaseProvider] = []\n",
        "        if getattr(self.config, \"newsapi_key\", None):\n",
        "            try:\n",
        "                providers.append(NewsAPIProvider(self.config.newsapi_key))\n",
        "            except Exception as exc:\n",
        "                print(f\"Skipping NewsAPI provider: {exc}\")\n",
        "        providers.append(WiredRSSProvider())\n",
        "        providers.append(MockProvider())\n",
        "        return providers\n",
        "\n",
        "    def search(self, query: str, limit: Optional[int] = None, **kwargs) -> List[NewsItem]:\n",
        "        if not query or not query.strip():\n",
        "            raise ValueError(\"Query must be provided\")\n",
        "        limit = limit or self.config.default_limit\n",
        "        seen_urls: set[str] = set()\n",
        "        seen_titles: set[str] = set()\n",
        "        results: List[NewsItem] = []\n",
        "        for provider in self.providers:\n",
        "            for raw in provider.fetch(query=query, limit=limit, **kwargs):\n",
        "                if raw.url:\n",
        "                    if raw.url in seen_urls:\n",
        "                        continue\n",
        "                    if not self._is_allowed_domain(raw.url):\n",
        "                        continue\n",
        "                    seen_urls.add(raw.url)\n",
        "                dedupe_key = self._dedupe_key(raw)\n",
        "                if dedupe_key and dedupe_key in seen_titles:\n",
        "                    continue\n",
        "                item = self._process(raw)\n",
        "                results.append(item)\n",
        "                if dedupe_key:\n",
        "                    seen_titles.add(dedupe_key)\n",
        "                if len(results) >= limit:\n",
        "                    return results\n",
        "        return results\n",
        "\n",
        "    def _process(self, article: RawArticle) -> NewsItem:\n",
        "        text = article.content or article.description\n",
        "        summary = summarize(text)\n",
        "        sentiment_label, sentiment_score = score_sentiment(text or \"\")\n",
        "        excerpt = article.description or article.content\n",
        "        if excerpt and len(excerpt) > 280:\n",
        "            excerpt = excerpt[:277].rstrip() + \"...\"\n",
        "        return NewsItem(\n",
        "            title=article.title,\n",
        "            url=article.url,\n",
        "            source=article.source,\n",
        "            published_at=article.published_at,\n",
        "            summary=summary,\n",
        "            sentiment=sentiment_label,\n",
        "            sentiment_score=sentiment_score,\n",
        "            excerpt=excerpt,\n",
        "        )\n",
        "\n",
        "    def _is_allowed_domain(self, url: str) -> bool:\n",
        "        if not self.config.allowed_domains:\n",
        "            return True\n",
        "        parsed = urlparse(url)\n",
        "        if not parsed.netloc:\n",
        "            return True\n",
        "        hostname = parsed.netloc.lower()\n",
        "        for domain in self.config.allowed_domains:\n",
        "            domain = domain.lower()\n",
        "            if hostname == domain or hostname.endswith(f\".{domain}\"):\n",
        "                return True\n",
        "        return False\n",
        "\n",
        "    def to_dict(self, item: NewsItem) -> dict:\n",
        "        data = asdict(item)\n",
        "        if item.published_at is not None:\n",
        "            data[\"published_at\"] = item.published_at.isoformat()\n",
        "        return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "config = AgentConfig.from_env()\n",
        "agent = NewsAgent(config=config)\n",
        "agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sample_items = agent.search(\"INFY\", limit=3)\n",
        "for idx, item in enumerate(sample_items, start=1):\n",
        "    print(f\"[{idx}] {item.title} - {item.sentiment} ({item.sentiment_score:.2f})\")\n",
        "    print(f\"    Source: {item.source}\")\n",
        "    if item.summary:\n",
        "        print(f\"    Summary: {item.summary}\")\n",
        "    elif item.excerpt:\n",
        "        print(f\"    Excerpt: {item.excerpt}\")\n",
        "    if item.url:\n",
        "        print(f\"    URL: {item.url}\")\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Optional: Flask App Snippet\n",
        "\n",
        "You can adapt the snippet below to run the Flask API inside the notebook by removing the guard and running the cell. It will block the kernel, so it's typically better to keep using `app.py` for serving requests."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from flask import Flask, jsonify, request\n",
        "\n",
        "app = Flask(__name__)\n",
        "_agent = agent\n",
        "\n",
        "@app.get(\"/health\")\n",
        "def healthcheck():\n",
        "    return {\"status\": \"ok\"}\n",
        "\n",
        "\n",
        "@app.post(\"/news\")\n",
        "def fetch_news():\n",
        "    payload = request.get_json(silent=True) or {}\n",
        "    query = payload.get(\"query\")\n",
        "    limit = payload.get(\"limit\")\n",
        "    if not query:\n",
        "        return jsonify({\"error\": \"`query` is required\"}), 400\n",
        "    try:\n",
        "        items = _agent.search(query=query, limit=limit)\n",
        "        return jsonify([_agent.to_dict(item) for item in items])\n",
        "    except ValueError as exc:\n",
        "        return jsonify({\"error\": str(exc)}), 400\n",
        "\n",
        "# To run inside notebook (blocks execution):\n",
        "# app.run(host=\"0.0.0.0\", port=8008, debug=True)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
